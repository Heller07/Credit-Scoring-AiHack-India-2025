{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13651759,"sourceType":"datasetVersion","datasetId":8678879}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ===============================================================\n# CREDIT SCORING ‚Äî ADVANCED FEATURE & HYPERPARAMETER TUNED MODEL\n# ===============================================================\n\nimport pandas as pd\nimport numpy as np\nimport xgboost as xgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\nimport optuna\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# ---------- Load Data ----------\ntrain = pd.read_csv(\"/kaggle/input/aiful-dataset/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/aiful-dataset/test.csv\")\nsample_submission = pd.read_csv(\"/kaggle/input/aiful-dataset/sample_submission.csv\")\nTARGET = \"Default 12 Flag\"\n\n# ---------- Basic Cleaning ----------\nfor df in [train, test]:\n    df['JIS Address Code'] = df['JIS Address Code'].fillna(-999).astype(int)\n    df['Application Date'] = pd.to_datetime(df['Application Date'])\n    df['Date of Birth'] = pd.to_datetime(df['Date of Birth'])\n    df['Application_Hour'] = df['Application Time'] // 10000\n    df['Application_Month'] = df['Application Date'].dt.month\n    df['Application_DayOfWeek'] = df['Application Date'].dt.dayofweek\n    df['Age'] = (df['Application Date'] - df['Date of Birth']).dt.days / 365.25\n\n# ---------- Financial Ratios ----------\nepsilon = 1e-6\nfor df in [train, test]:\n    df['MONTHLY_INCOME'] = df['Total Annual Income'] / 12\n    df['LOAN_TO_INCOME_RATIO'] = df['Application Limit Amount(Desired)'] / (df['Total Annual Income'] + epsilon)\n    df['DECLARED_DEBT_TO_INCOME_RATIO'] = df['Declared Amount of Unsecured Loans'] / (df['Total Annual Income'] + epsilon)\n    df['ACTUAL_DEBT_TO_INCOME_RATIO'] = df['Amount of Unsecured Loans'] / (df['Total Annual Income'] + epsilon)\n    df['RENT_TO_INCOME'] = df['Rent Burden Amount'] / (df['MONTHLY_INCOME'] + epsilon)\n    df['AGE_BUCKET'] = pd.cut(df['Age'], bins=[0,25,35,45,55,100], labels=[0,1,2,3,4]).astype(int)\n\n# ---------- Stability & Employment ----------\nfor df in [train, test]:\n    df['EMPLOYMENT_YEARS'] = df['Duration of Employment at Company (Months)'] / 12\n    df['STABILITY_RATIO'] = df['EMPLOYMENT_YEARS'] / (df['Age'] + epsilon)\n    df['INCOME_PER_DEPENDENT'] = df['Total Annual Income'] / (df['Number of Dependents'] + 1)\n    df['INCOME_PER_AGE'] = df['Total Annual Income'] / (df['Age'] + epsilon)\n\n# ---------- Advanced Financial Features ----------\nfor df in [train, test]:\n    df['DECLARED_VS_ACTUAL_RATIO'] = df['Declared Amount of Unsecured Loans'] / (df['Amount of Unsecured Loans'] + epsilon)\n    df['AVG_LOAN_TO_LIMIT'] = (df['Amount of Unsecured Loans'] / (df['Number of Unsecured Loans'] + 1)) / (df['Application Limit Amount(Desired)'] + epsilon)\n    df['AVG_RENT_BURDEN_RATIO'] = df['Rent Burden Amount'] / (df['Declared Amount of Unsecured Loans'] + 1)\n    df['LIQUIDITY_SCORE'] = df['Total Annual Income'] / (df['Rent Burden Amount'] + df['Amount of Unsecured Loans'] + epsilon)\n    df['FIN_STABILITY_SCORE'] = df['EMPLOYMENT_YEARS'] * df['INCOME_PER_AGE']\n    df['BURDEN_SCORE'] = df['RENT_TO_INCOME'] + df['LOAN_TO_INCOME_RATIO'] + df['ACTUAL_DEBT_TO_INCOME_RATIO']\n\n# ---------- Group Normalization ----------\ngroup_cols = ['JIS Address Code', 'Industry Type', 'Employment Type']\nagg_cols = ['Total Annual Income', 'ACTUAL_DEBT_TO_INCOME_RATIO']\n\nfor gcol in group_cols:\n    for acol in agg_cols:\n        stats = train.groupby(gcol)[acol].mean().reset_index()\n        stats.rename(columns={acol: f\"{acol}_{gcol}_mean\"}, inplace=True)\n        train = train.merge(stats, on=gcol, how='left')\n        test = test.merge(stats, on=gcol, how='left')\n        train[f\"{acol}_to_{gcol}_rel\"] = train[acol] / (train[f\"{acol}_{gcol}_mean\"] + epsilon)\n        test[f\"{acol}_to_{gcol}_rel\"] = test[acol] / (test[f\"{acol}_{gcol}_mean\"] + epsilon)\n\n# ---------- Risk Buckets ----------\nfor df in [train, test]:\n    df['INCOME_BUCKET'] = pd.qcut(df['Total Annual Income'], 5, labels=False, duplicates='drop')\n    df['DEBT_BUCKET'] = pd.qcut(df['ACTUAL_DEBT_TO_INCOME_RATIO'], 5, labels=False, duplicates='drop')\n    df['LOAN_BUCKET'] = pd.qcut(df['LOAN_TO_INCOME_RATIO'], 5, labels=False, duplicates='drop')\n\n# ---------- Interactions ----------\nfor df in [train, test]:\n    df['DEBT_X_EMP'] = df['ACTUAL_DEBT_TO_INCOME_RATIO'] * df['EMPLOYMENT_YEARS']\n    df['DEBT_X_AGE'] = df['ACTUAL_DEBT_TO_INCOME_RATIO'] * df['Age']\n    df['INCOME_X_EMP'] = df['Total Annual Income'] * df['EMPLOYMENT_YEARS']\n    df['INCOME_X_RENT'] = df['Total Annual Income'] / (df['Rent Burden Amount'] + 1)\n\n# ---------- Label Encoding ----------\ncat_cols = [\n    'Major Media Code', 'Internet Details', 'Reception Type Category', 'Gender',\n    'Single/Married Status', 'Residence Type', 'Employment Type',\n    'Industry Type', 'Company Size Category', 'AGE_BUCKET', \n    'INCOME_BUCKET', 'DEBT_BUCKET', 'LOAN_BUCKET'\n]\n\nfor col in cat_cols:\n    if col in train.columns:\n        le = LabelEncoder()\n        full = pd.concat([train[col].astype(str), test[col].astype(str)], axis=0)\n        le.fit(full)\n        train[col] = le.transform(train[col].astype(str))\n        test[col] = le.transform(test[col].astype(str))\n\n# ---------- Feature Selection ----------\ndrop_cols = [TARGET, 'Application Date', 'Date of Birth', 'Application Time']\nfeatures = [c for c in train.columns if c not in drop_cols]\n\nX, y = train[features], train[TARGET]\nX_test = test[features]\n\n# ---------- Optuna Hyperparameter Optimization ----------\ndef objective(trial):\n    params = {\n        'objective': 'binary:logistic',\n        'eval_metric': 'auc',\n        'learning_rate': trial.suggest_float(\"learning_rate\", 0.01, 0.08),\n        'max_depth': trial.suggest_int(\"max_depth\", 5, 10),\n        'min_child_weight': trial.suggest_int(\"min_child_weight\", 5, 50),\n        'subsample': trial.suggest_float(\"subsample\", 0.6, 0.95),\n        'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.6, 0.95),\n        'reg_lambda': trial.suggest_float(\"reg_lambda\", 1, 8),\n        'reg_alpha': trial.suggest_float(\"reg_alpha\", 0, 5),\n        'tree_method': 'gpu_hist',\n        'predictor': 'gpu_predictor',\n        'random_state': 42,\n    }\n\n    folds = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n    oof_preds = np.zeros(len(X))\n\n    for tr_idx, val_idx in folds.split(X, y):\n        X_train, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n        y_train, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n        dtrain = xgb.DMatrix(X_train, label=y_train)\n        dval = xgb.DMatrix(X_val, label=y_val)\n\n        model = xgb.train(\n            params,\n            dtrain,\n            num_boost_round=2000,\n            evals=[(dval, \"valid\")],\n            early_stopping_rounds=100,\n            verbose_eval=False,\n        )\n        oof_preds[val_idx] = model.predict(dval)\n\n    auc = roc_auc_score(y, oof_preds)\n    return auc\n\nprint(\"\\nüîç Starting Optuna Tuning (this may take ~10-20 mins)...\")\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=30)\n\nprint(\"‚úÖ Best Trial:\", study.best_trial.params)\n\n# ---------- Final Model Training ----------\nparams = study.best_trial.params\nparams.update({'objective': 'binary:logistic', 'eval_metric': 'auc', 'tree_method': 'gpu_hist'})\n\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\noof_preds = np.zeros(len(X))\nsub_preds = np.zeros(len(X_test))\n\nfor fold, (tr_idx, val_idx) in enumerate(folds.split(X, y)):\n    print(f\"\\n===== Fold {fold+1} =====\")\n    X_train, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n    y_train, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n\n    dtrain = xgb.DMatrix(X_train, label=y_train)\n    dval = xgb.DMatrix(X_val, label=y_val)\n    dtest = xgb.DMatrix(X_test)\n\n    model = xgb.train(\n        params,\n        dtrain,\n        num_boost_round=4000,\n        evals=[(dval, \"valid\")],\n        early_stopping_rounds=100,\n        verbose_eval=250\n    )\n\n    oof_preds[val_idx] = model.predict(dval)\n    sub_preds += model.predict(dtest) / folds.n_splits\n\nauc = roc_auc_score(y, oof_preds)\nprint(f\"\\n‚úÖ Final OOF ROC-AUC: {auc:.4f}\")\n\nsample_submission[TARGET] = sub_preds\nsample_submission.to_csv(\"submission_xgb_optuna.csv\", index=False)\nprint(\"‚úÖ Submission saved as: submission_xgb_optuna.csv\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-08T09:25:37.029355Z","iopub.execute_input":"2025-11-08T09:25:37.029919Z","iopub.status.idle":"2025-11-08T09:30:01.002704Z","shell.execute_reply.started":"2025-11-08T09:25:37.029894Z","shell.execute_reply":"2025-11-08T09:30:01.002079Z"}},"outputs":[{"name":"stderr","text":"[I 2025-11-08 09:25:44,226] A new study created in memory with name: no-name-d61ce1c1-fbe2-4a10-ad56-1d338c824105\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Starting Optuna Tuning (this may take ~10-20 mins)...\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-11-08 09:25:50,349] Trial 0 finished with value: 0.6637539077937014 and parameters: {'learning_rate': 0.0564987503288643, 'max_depth': 10, 'min_child_weight': 20, 'subsample': 0.8692801340772867, 'colsample_bytree': 0.691709929961124, 'reg_lambda': 7.366751111153972, 'reg_alpha': 1.2594482709139783}. Best is trial 0 with value: 0.6637539077937014.\n[I 2025-11-08 09:25:56,366] Trial 1 finished with value: 0.672389278295673 and parameters: {'learning_rate': 0.025227122518013158, 'max_depth': 6, 'min_child_weight': 39, 'subsample': 0.7176590325573209, 'colsample_bytree': 0.7775296806773826, 'reg_lambda': 7.37894259718327, 'reg_alpha': 0.24023856618309136}. Best is trial 1 with value: 0.672389278295673.\n[I 2025-11-08 09:26:01,312] Trial 2 finished with value: 0.6647445071041147 and parameters: {'learning_rate': 0.06449243596292285, 'max_depth': 8, 'min_child_weight': 13, 'subsample': 0.611601155385176, 'colsample_bytree': 0.7550462875331687, 'reg_lambda': 5.41981332372733, 'reg_alpha': 4.809830862032803}. Best is trial 1 with value: 0.672389278295673.\n[I 2025-11-08 09:26:05,935] Trial 3 finished with value: 0.6613350541935971 and parameters: {'learning_rate': 0.07224994405612656, 'max_depth': 9, 'min_child_weight': 20, 'subsample': 0.8377721830836731, 'colsample_bytree': 0.8678379484610821, 'reg_lambda': 2.1512562907325883, 'reg_alpha': 0.8892599640420179}. Best is trial 1 with value: 0.672389278295673.\n[I 2025-11-08 09:26:16,056] Trial 4 finished with value: 0.6706542318973205 and parameters: {'learning_rate': 0.022254079031363033, 'max_depth': 9, 'min_child_weight': 24, 'subsample': 0.8245032536796792, 'colsample_bytree': 0.8401802138527042, 'reg_lambda': 6.106144003621464, 'reg_alpha': 3.5680442089170383}. Best is trial 1 with value: 0.672389278295673.\n[I 2025-11-08 09:26:29,169] Trial 5 finished with value: 0.6742047168721605 and parameters: {'learning_rate': 0.010314659908990718, 'max_depth': 6, 'min_child_weight': 20, 'subsample': 0.7379285740580522, 'colsample_bytree': 0.7907747042491868, 'reg_lambda': 1.1366615913001112, 'reg_alpha': 0.352491328161354}. Best is trial 5 with value: 0.6742047168721605.\n[I 2025-11-08 09:26:33,144] Trial 6 finished with value: 0.664771603084765 and parameters: {'learning_rate': 0.06647505093563161, 'max_depth': 9, 'min_child_weight': 24, 'subsample': 0.7535357710034328, 'colsample_bytree': 0.6954460267953166, 'reg_lambda': 5.073556715850478, 'reg_alpha': 1.55672152003274}. Best is trial 5 with value: 0.6742047168721605.\n[I 2025-11-08 09:26:42,561] Trial 7 finished with value: 0.669629353875115 and parameters: {'learning_rate': 0.02189508910910784, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.907756147982659, 'colsample_bytree': 0.892886538892425, 'reg_lambda': 2.029410195949997, 'reg_alpha': 2.89955968458392}. Best is trial 5 with value: 0.6742047168721605.\n[I 2025-11-08 09:26:57,569] Trial 8 finished with value: 0.6699783702255848 and parameters: {'learning_rate': 0.01651061573000099, 'max_depth': 10, 'min_child_weight': 14, 'subsample': 0.8460963497745221, 'colsample_bytree': 0.9203058002514387, 'reg_lambda': 4.77729050322859, 'reg_alpha': 4.916190467428867}. Best is trial 5 with value: 0.6742047168721605.\n[I 2025-11-08 09:27:01,044] Trial 9 finished with value: 0.6671205652380247 and parameters: {'learning_rate': 0.06291624390218738, 'max_depth': 6, 'min_child_weight': 12, 'subsample': 0.6191426153731214, 'colsample_bytree': 0.6864519099765659, 'reg_lambda': 1.586906353383328, 'reg_alpha': 2.7502011980859016}. Best is trial 5 with value: 0.6742047168721605.\n[I 2025-11-08 09:27:05,236] Trial 10 finished with value: 0.672054363227143 and parameters: {'learning_rate': 0.039317849012883835, 'max_depth': 5, 'min_child_weight': 36, 'subsample': 0.7036031007154205, 'colsample_bytree': 0.6068500446800931, 'reg_lambda': 3.322987802605788, 'reg_alpha': 0.14745908626106408}. Best is trial 5 with value: 0.6742047168721605.\n[I 2025-11-08 09:27:18,904] Trial 11 finished with value: 0.6738371615348331 and parameters: {'learning_rate': 0.01018626841802832, 'max_depth': 6, 'min_child_weight': 50, 'subsample': 0.7004865935591774, 'colsample_bytree': 0.8018416156757705, 'reg_lambda': 7.617047796613938, 'reg_alpha': 0.19152014281936836}. Best is trial 5 with value: 0.6742047168721605.\n[I 2025-11-08 09:27:33,306] Trial 12 finished with value: 0.6739181170644304 and parameters: {'learning_rate': 0.010066397610548554, 'max_depth': 6, 'min_child_weight': 49, 'subsample': 0.6768810116080269, 'colsample_bytree': 0.8056163561602115, 'reg_lambda': 3.9842478311124294, 'reg_alpha': 1.9082324428382824}. Best is trial 5 with value: 0.6742047168721605.\n[I 2025-11-08 09:27:37,936] Trial 13 finished with value: 0.6716583253997439 and parameters: {'learning_rate': 0.03682561700574416, 'max_depth': 5, 'min_child_weight': 34, 'subsample': 0.6559882708950077, 'colsample_bytree': 0.8222471905082483, 'reg_lambda': 3.5085339120508476, 'reg_alpha': 1.9356244173806734}. Best is trial 5 with value: 0.6742047168721605.\n[I 2025-11-08 09:27:51,369] Trial 14 finished with value: 0.6733250295677727 and parameters: {'learning_rate': 0.010813177214509468, 'max_depth': 7, 'min_child_weight': 50, 'subsample': 0.7822403549503496, 'colsample_bytree': 0.735336286336346, 'reg_lambda': 3.461089944668749, 'reg_alpha': 2.046214689522858}. Best is trial 5 with value: 0.6742047168721605.\n[I 2025-11-08 09:27:56,459] Trial 15 finished with value: 0.6713673080067907 and parameters: {'learning_rate': 0.031450806944485106, 'max_depth': 7, 'min_child_weight': 42, 'subsample': 0.6621288729322445, 'colsample_bytree': 0.9400963185664848, 'reg_lambda': 2.4177163039142973, 'reg_alpha': 3.6276254736189695}. Best is trial 5 with value: 0.6742047168721605.\n[I 2025-11-08 09:28:00,107] Trial 16 finished with value: 0.6691490092767347 and parameters: {'learning_rate': 0.05294159388014114, 'max_depth': 6, 'min_child_weight': 30, 'subsample': 0.7548107579497811, 'colsample_bytree': 0.8557202438952707, 'reg_lambda': 1.0990822866064387, 'reg_alpha': 0.8676530464941218}. Best is trial 5 with value: 0.6742047168721605.\n[I 2025-11-08 09:28:04,621] Trial 17 finished with value: 0.6709136053837672 and parameters: {'learning_rate': 0.046936352222731126, 'max_depth': 5, 'min_child_weight': 43, 'subsample': 0.7930822862637384, 'colsample_bytree': 0.789654068058173, 'reg_lambda': 2.9185218439439096, 'reg_alpha': 0.8377343498409182}. Best is trial 5 with value: 0.6742047168721605.\n[I 2025-11-08 09:28:10,604] Trial 18 finished with value: 0.6719787674093601 and parameters: {'learning_rate': 0.029771132750448105, 'max_depth': 7, 'min_child_weight': 30, 'subsample': 0.6605659734109566, 'colsample_bytree': 0.7270068835631186, 'reg_lambda': 6.3817654243587105, 'reg_alpha': 2.281551616068388}. Best is trial 5 with value: 0.6742047168721605.\n[I 2025-11-08 09:28:20,975] Trial 19 finished with value: 0.6733192928303682 and parameters: {'learning_rate': 0.015258344135558616, 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.726365332614715, 'colsample_bytree': 0.6079819138825893, 'reg_lambda': 4.152812092527562, 'reg_alpha': 3.4969761890307227}. Best is trial 5 with value: 0.6742047168721605.\n[I 2025-11-08 09:28:24,138] Trial 20 finished with value: 0.6700440706524682 and parameters: {'learning_rate': 0.07858057666049172, 'max_depth': 5, 'min_child_weight': 45, 'subsample': 0.9281961141507269, 'colsample_bytree': 0.819998804281175, 'reg_lambda': 4.130177941754907, 'reg_alpha': 1.5657754726890767}. Best is trial 5 with value: 0.6742047168721605.\n[I 2025-11-08 09:28:37,358] Trial 21 finished with value: 0.6736572293522369 and parameters: {'learning_rate': 0.010898466600735044, 'max_depth': 6, 'min_child_weight': 50, 'subsample': 0.6895928461495059, 'colsample_bytree': 0.8002942422447665, 'reg_lambda': 7.876020411105927, 'reg_alpha': 0.00973926329854291}. Best is trial 5 with value: 0.6742047168721605.\n[I 2025-11-08 09:28:46,715] Trial 22 finished with value: 0.6740508746854607 and parameters: {'learning_rate': 0.01603874749978291, 'max_depth': 7, 'min_child_weight': 47, 'subsample': 0.690502123573363, 'colsample_bytree': 0.8099889338216083, 'reg_lambda': 5.992304908006787, 'reg_alpha': 0.5844802592130192}. Best is trial 5 with value: 0.6742047168721605.\n[I 2025-11-08 09:28:54,081] Trial 23 finished with value: 0.6733660195100263 and parameters: {'learning_rate': 0.01904717394191471, 'max_depth': 7, 'min_child_weight': 45, 'subsample': 0.749054177343915, 'colsample_bytree': 0.8758493209886418, 'reg_lambda': 6.0243663733458686, 'reg_alpha': 0.475491912545594}. Best is trial 5 with value: 0.6742047168721605.\n[I 2025-11-08 09:29:00,329] Trial 24 finished with value: 0.6724931344121126 and parameters: {'learning_rate': 0.027638608411308233, 'max_depth': 8, 'min_child_weight': 38, 'subsample': 0.6767492740896441, 'colsample_bytree': 0.760727444206583, 'reg_lambda': 6.715006554154066, 'reg_alpha': 1.112770909670259}. Best is trial 5 with value: 0.6742047168721605.\n[I 2025-11-08 09:29:08,957] Trial 25 finished with value: 0.672754094730162 and parameters: {'learning_rate': 0.01720870513897967, 'max_depth': 7, 'min_child_weight': 19, 'subsample': 0.6444723078736415, 'colsample_bytree': 0.8344897734854677, 'reg_lambda': 5.568773042316099, 'reg_alpha': 0.5734609586619616}. Best is trial 5 with value: 0.6742047168721605.\n[I 2025-11-08 09:29:18,861] Trial 26 finished with value: 0.673322254799391 and parameters: {'learning_rate': 0.01441357579281322, 'max_depth': 6, 'min_child_weight': 47, 'subsample': 0.7302941508064976, 'colsample_bytree': 0.7310913386120866, 'reg_lambda': 4.194558880509836, 'reg_alpha': 1.5144013626253345}. Best is trial 5 with value: 0.6742047168721605.\n[I 2025-11-08 09:29:24,223] Trial 27 finished with value: 0.671299367295599 and parameters: {'learning_rate': 0.035479294287449795, 'max_depth': 7, 'min_child_weight': 33, 'subsample': 0.6824363481494072, 'colsample_bytree': 0.6438123298169716, 'reg_lambda': 6.854989725628449, 'reg_alpha': 0.620265646509855}. Best is trial 5 with value: 0.6742047168721605.\n[I 2025-11-08 09:29:30,385] Trial 28 finished with value: 0.6738989806101058 and parameters: {'learning_rate': 0.022265252539424032, 'max_depth': 5, 'min_child_weight': 25, 'subsample': 0.6310579969557077, 'colsample_bytree': 0.8995675632341005, 'reg_lambda': 1.2046442974502918, 'reg_alpha': 3.0404551402206064}. Best is trial 5 with value: 0.6742047168721605.\n[I 2025-11-08 09:29:35,016] Trial 29 finished with value: 0.6706042020885926 and parameters: {'learning_rate': 0.043530576523963825, 'max_depth': 8, 'min_child_weight': 41, 'subsample': 0.7851727556316342, 'colsample_bytree': 0.7649522975745457, 'reg_lambda': 2.8774534767886486, 'reg_alpha': 1.2452417315296147}. Best is trial 5 with value: 0.6742047168721605.\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Best Trial: {'learning_rate': 0.010314659908990718, 'max_depth': 6, 'min_child_weight': 20, 'subsample': 0.7379285740580522, 'colsample_bytree': 0.7907747042491868, 'reg_lambda': 1.1366615913001112, 'reg_alpha': 0.352491328161354}\n\n===== Fold 1 =====\n[0]\tvalid-auc:0.62512\n[250]\tvalid-auc:0.67450\n[500]\tvalid-auc:0.67990\n[750]\tvalid-auc:0.68161\n[971]\tvalid-auc:0.68134\n\n===== Fold 2 =====\n[0]\tvalid-auc:0.62194\n[250]\tvalid-auc:0.66731\n[500]\tvalid-auc:0.67076\n[750]\tvalid-auc:0.67138\n[892]\tvalid-auc:0.67136\n\n===== Fold 3 =====\n[0]\tvalid-auc:0.62919\n[250]\tvalid-auc:0.66611\n[500]\tvalid-auc:0.66941\n[750]\tvalid-auc:0.67026\n[1000]\tvalid-auc:0.67085\n[1216]\tvalid-auc:0.67104\n\n===== Fold 4 =====\n[0]\tvalid-auc:0.62061\n[250]\tvalid-auc:0.66154\n[500]\tvalid-auc:0.66801\n[750]\tvalid-auc:0.67032\n[1000]\tvalid-auc:0.67115\n[1250]\tvalid-auc:0.67190\n[1500]\tvalid-auc:0.67220\n[1634]\tvalid-auc:0.67195\n\n===== Fold 5 =====\n[0]\tvalid-auc:0.63143\n[250]\tvalid-auc:0.66897\n[500]\tvalid-auc:0.67314\n[750]\tvalid-auc:0.67381\n[888]\tvalid-auc:0.67338\n\n‚úÖ Final OOF ROC-AUC: 0.6736\n‚úÖ Submission saved as: submission_xgb_optuna.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}